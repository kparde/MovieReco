{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommendations\n",
    "\n",
    "Process: \n",
    "- Input precomputed rating predictions \n",
    "- Limit to user\n",
    "- Merge with movie ratings to get weighted average of ratings of each movie\n",
    "- Sort first on similarity score (prediction) and secondarily on weighted average (first merge with movies_ratings) if same prediction\n",
    "\n",
    "If precision = True, then instead of using precomputed predictions, fit KNN baseline model on train ratings data and then generate predictions for test ratings data. Produce test predictions for calculating precision and recall. \n",
    "    \n",
    "Parameters:\n",
    "- user_id: ID of user to generate recommendations for\n",
    "- ratings: ratings data for each user (movies rated + star ratings)\n",
    "- movies_ratings: df of movieIds with weighted average of count and average rating. Used to secondarily sort if same prediction from recommendation model\n",
    "- df2: \n",
    "    - precision = False: pregenerated collaborative filtering predictions.\n",
    "    - precision = True: test set of ratings data to generate predicitons on for precision, recall calculation\n",
    "- keep_movies1, keep_movies2, : [] -- dummy parameter so that this funciton as the same inputs as the other recommendation models\n",
    "- df1, movieIds, content_recommendation_system, collab_recommenation_system = False: dummy parameters so that this funciton as the same inputs as the other recommendation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import scipy.spatial.distance as distance\n",
    "from sklearn import metrics \n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import fastparquet\n",
    "import pickle\n",
    "import scipy\n",
    "import sklearn\n",
    "from surprise import SVD, Dataset, Reader, KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_recommendations(user_id, df1, ratings, movieIds, movies_ratings, keep_movies1, df2,\n",
    "                           keep_movies2, content_recommedation_system = False, collab_recommendation_system = False,\n",
    "                           top_n = 10, precision = False):\n",
    "    \n",
    "    # generate recommendations on train/test set\n",
    "    if precision: \n",
    "        test_ratings = df2.copy()\n",
    "        # set parameters for KNN model\n",
    "        user_based = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }\n",
    "        collab_ratings = ratings[['userId','movieId','rating']]\n",
    "        # set scale between min and max rating \n",
    "        min_rat = collab_ratings.rating.min()\n",
    "        max_rat = collab_ratings.rating.max()\n",
    "        reader = Reader(rating_scale=(min_rat,max_rat))\n",
    "        # fit on train set\n",
    "        data = Dataset.load_from_df(collab_ratings, reader)\n",
    "        trainset = data.build_full_trainset()\n",
    "        algo = KNNBaseline(sim_options=user_based)\n",
    "        algo.fit(trainset)\n",
    "\n",
    "        # predict on test set\n",
    "        test_ratings = test_ratings[['userId','movieId','rating']]\n",
    "        testset = [tuple(x) for x in test_ratings.to_numpy()]\n",
    "        predictions = algo.test(testset)\n",
    "        \n",
    "        # return predictions on test set \n",
    "        collab_predictions = pd.DataFrame(predictions)\n",
    "        collab_predictions=collab_predictions[['uid','iid','est']]\n",
    "        collab_predictions= collab_predictions.rename(columns = {'est':'prediction', 'uid':'userId', 'iid':'movieId'}\n",
    "                                                     )[['userId','movieId','prediction']]\n",
    "        collab_predictions[['userId','movieId']] = collab_predictions[['userId','movieId']].astype(int)\n",
    "        \n",
    "    # use precomputed\n",
    "    else:\n",
    "        collab_predictions = df2.copy()\n",
    "\n",
    "    # get recommendations from collab filtering model \n",
    "    collab_rec = collab_predictions[collab_predictions.userId == user_id]\n",
    "    # merge with movie ratings + sort on prediction and secondarily on weighted average of ratings\n",
    "    collab_rec = pd.merge(collab_rec, movies_ratings, on = 'movieId')\n",
    "    collab_rec = collab_rec.sort_values(['prediction', 'weighted_avg'], ascending = [False, True])\n",
    "    \n",
    "    return collab_rec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
