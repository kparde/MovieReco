{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Evaluate Recommendation Models\n",
    "Functionalized code such that different content models are imported as modules and then standard evaluation functions are called and the results are saved to a text file.   \n",
    "The following markdown describes the various parameters that must be set depending on the model being evaluated \n",
    "\n",
    "- 5 metrics: personalization, precision & recall @K, personal diversity, global diversity, average rating \n",
    "- For all metrics, calculate on a random subset of users and take average value. For personalization, take average across k sets (folds) of random users because comparing users to each other.    \n",
    "- Set seeds such that evaluate different models on the same set of users \n",
    "- Record results from each model in a text file to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Described more thoroughly with visualizations of matrix multiplication in Methodological Appendix\n",
    "\n",
    "- Personalized recommendations: provide materially different sets of recommendations for different users\n",
    "- Accurate recommendations: high precision and recall based on test/train split of user ratings\n",
    "- Personal diversity: provide variety of recommendations to each individual user\n",
    "- Average rating: recommend high quality movies with high average ratings\n",
    "- Global diversity: recommend movies in the long tail. Do not only recommend popular movies because this will not increase overall viewership, engagement with the streaming platform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow of Model Building/Testing\n",
    "1. Content models with different combinations of metadata\n",
    "2. Combined content models where some subset of movies are evaluated using one model and another subset with another\n",
    "    - Best result is used for item-item recommendations in UI\n",
    "3. Collaboartive Filtering Models\n",
    "4. Combined collaborative filtering and content models where some subset of movies are evaluated with collaborative filtering and another subset with a content model \n",
    "    - Best result is used for personalized recommendations in UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To: Import Recommendation System\n",
    "\n",
    "1)  Convert recommendation system notebook to .py\n",
    "\n",
    "2) Import function using:\n",
    "\n",
    "from <name.py> import <name of the recomendation function>\n",
    "    \n",
    "example: from contentbasedrecommendationsystem import user_content_recommendations\n",
    "    \n",
    "3) recommendation_system: give the name of the recommendation system, you want to get the evaluations for   \n",
    "    \n",
    "    \n",
    "## How to: Run different types of models\n",
    "- Individual content model with full data:\n",
    "    - df1 = sparse dataset\n",
    "    - cols1 = columns from df1\n",
    "    - movieIds = moviesIds (row names) from df1\n",
    "    - keep_movies = movieIds  \n",
    "    - keep_movies1 = []\n",
    "    - keep_movies2 = []\n",
    "    - recommendation_system = content_based_recommendations.user_content_recommendations\n",
    "    - df2 = False, cols2 = False, recommendation_system_input1, recommendation_system_input2 = False\n",
    "    - list_user = set(ratings.userId)\n",
    "- Individual content model with specific subsets of movies:\n",
    "    - keep_movies = subset of movies (likely either movieIds_tags or movieIds_notags)\n",
    "        - Evaluate on subset\n",
    "    - keep_movies1 = same subset \n",
    "        - Generate recommendations only from subset\n",
    "    - Else same\n",
    "- Combined content model with two different input datasets\n",
    "    - df1 = sparse dataset1 , df2 = sparse dataset2\n",
    "    - cols1 = columns from df1, col2 = columns from df2\n",
    "    - keep_movies = movieIds  (evaluate on all movies)\n",
    "    - keep_movies1 = subset 1\n",
    "    - keep_movies2 = subset 2\n",
    "    - keep_movies = movieIds (row names) from df1 or df2 -- identical \n",
    "    - recommendation_system_input1 = content_based_recommendations.user_content_recommendations\n",
    "    - recommendation_system_input2 = False\n",
    "    - recommendation_system = content_based_recommendations_combine.content_models_combine\n",
    "    - list_user = set(ratings.userId)\n",
    "- Collaborative model\n",
    "    - df1 = sparse dataset1 (baseline content) \n",
    "        - Evaluate personal diversity based on baseline features\n",
    "    - df2 = collaborative filtering pretrained\n",
    "    - keep_movies = collab_predictions.movieId.unique()\n",
    "    - keep_movies1, keep_movies2 = []\n",
    "    - recommendation_system = collab_recommendations.collab_recommendations\n",
    "    - df1, cols1, recommendation_system_input1, recommendation_system_input2 = False\n",
    "    - list_user = set(collab_predictions.userId)\n",
    "- Combined content and collaborative model\n",
    "    - df1 = sparse dataset1, df2 = collab_predictions (pre-computed predictions)\n",
    "    - keep_movies = movieIds \n",
    "    - keep_movies1, keep_movies2 = []\n",
    "        - Kept movies calculated at a user level\n",
    "    - recommendation_system_input1 = content_based_recommendations.user_content_recommendations\n",
    "    - recommendation_system_input2 = collab_recommendations.collab_recommendations\n",
    "    - recommendation_system = recommendation_system = collab_content_recommendations_combine.collab_content_combine\n",
    "    - list_user = set(collab_predictions.userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Summary\n",
    "List text file titles and (sparse dataframe) for each model. See Methodological Appendix for full summary of results and conclusions. \n",
    "\n",
    "### Content Models \n",
    "- content_initial_eval.txt (processed_df_sparse): genre, actor, director. Cosine similarity between movies\n",
    "- contentv2_noMovieNorm_eval.txt (processed_df_sparse): same data, but no normalization of movie vector (true for all others)\n",
    "- content_all_meta_eval.txt (processed_df_all_meta_sparse): genre, actor, director, decade, country, production company \n",
    "    - Try also with each individual feature in the \"all\" version: content_<genre, actors_directors, decade, country, production>_eval.txt\n",
    "- content_baseline_plus_prod_eval.txt: genre, actors, director, production company \n",
    "    - country and decade individually perform poorly individually\n",
    "- content_desc_eval.txt (processed_df_desc): top 5 TF-IDF tokens from movie description\n",
    "    - Add Genre tokens: content_desc_genre_eval.txt (processed_df_desc_genre_sparse): description tokens and genre\n",
    "- content_tags_eval (processed_df_tags_sparse): top 5 TF-IDF genome tags\n",
    "- content_tags_rel_eval.txt (processed_df_tags_rel_sparse): top 5 genome tags by relevance score\n",
    "- content_baseline_tags_rel_eval.txt (processed_df_baseline_tags_rel_sparse): top 5 tags by relevance + baseline features\n",
    "- content_text_eval.txt (processed_df_text_sparse): top 5 TF-IDF text field (tags + description)\n",
    "\n",
    "### Combined Content Models\n",
    "(1) Evaluate models on relevant dataset     \n",
    "- content_tags_rel_only_eval.txt (processed_df_tags_rel_sparse + keep_cols = movieIds_tags): top 5 genome tags by relevance score ONLY with movies that have tags\n",
    "- content_tags_only_eval.txt (processed_df_tags_sparse + keep_cols = movieIds_tags): top 5 genome tags by tfidf ONLY with movies that have tags\n",
    "- content_text_tagsonly_eval.txt (processed_df_text_sparse + keep_cols = movieIds_tags): top 5 tags+description fields by tfidf ONLY with movies that have tags\n",
    "- content_baseline_notags_eval.txt (processed_df_sparse + keep_cols = movieIds_notags): baseline model (genre, actor, director) only for movies without tags (long tail) \n",
    "\n",
    "(2) Evaluate combined models on full dataset   \n",
    "- content_twomodels_tags_rel_eval.txt: combination of content_baseline_notags_eval and content_tags_rel_only_eval models using content_based_recommendations_combine system\n",
    "- content_twomodels_tags_eval.txt: combination of content_baseline_notags_eval and content_tags_only_eval models using content_based_recommendations_combine system\n",
    "- content_twomodels_text_eval.txt: combination of content_baseline_notags_eval and content_text_tagsonly_eval models using content_based_recommendations_combine system\n",
    "\n",
    "### Collaborative Filtering \n",
    "- Evaluation_collaborative_filtering_model_svdpp.txt: SVDpp model \n",
    "- collaborative_with_sim_msd.txt: KNNbaseline with Mean Squared Difference similarity\n",
    "- collaborative_with_sim_pearson_baseline.txt: KNNbaseline with Pearson correlation coefficient similarity \n",
    "\n",
    "### Combined Collaborative Filtering, Content Models\n",
    "(1) Which content model to use for movies not in collaborative filtering\n",
    "- content_baseline_nocollab_eval.txt: Baseline content model on movies not included in collaborative filtering predictions\n",
    "    - keep_movies = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies1 = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "    - list_user = set(collab_predictions.userId)\n",
    "- content_combined_tags_nocollab_eval.txt: Combined text model on movies not included in collaborative filtering \n",
    "    - keep_movies = set(movieIds).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies1 = set(movieIds_notags).difference(set(collab_predictions.movieId.unique())) \n",
    "    - keep_movies2 = set(movieIds_tags).difference(set(collab_predictions.movieId.unique())) \n",
    "    - list_user = set(collab_predictions.userId)\n",
    "  \n",
    "(2) Combined content and collaborative filtering model \n",
    "- collab_content_combine_5000users.txt: combination of content_baseline_nocollab_eval and best collaborative model using collab_content_combine system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import scipy.spatial.distance as distance\n",
    "from sklearn import metrics \n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import fastparquet\n",
    "import pickle\n",
    "import scipy\n",
    "import sklearn\n",
    "from surprise import SVD, Dataset, Reader, KNNBaseline\n",
    "import recommendation_models.content_based_recommendations\n",
    "import recommendation_models.content_based_recommendations_combine\n",
    "import recommendation_models.collab_content_recommendations_combine\n",
    "import recommendation_models.collab_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings and movie ratings aggregation data\n",
    "ratings = pd.read_parquet('processed_files/ratings_sample.parq')\n",
    "ratings = ratings.reset_index()\n",
    "movies_ratings = pd.read_parquet('processed_files/movies_ratings.parq')\n",
    "movies_ratings = movies_ratings.rename(columns={\"avg\": \"Average_Ratings\"})\n",
    "movies_ratings['weighted_avg'] = movies_ratings.cnt * movies_ratings.Average_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify sparse matricies of features to use for content attributes \n",
    "df1 = scipy.sparse.load_npz(\"processed_files/processed_df_sparse.npz\")\n",
    "#df1 = scipy.sparse.load_npz(\"processed_files/processed_df_text_sparse.npz\")\n",
    "#df2 = False\n",
    "\n",
    "# preloaded collaborative filtering predictions\n",
    "collab_predictions = pd.read_parquet('processed_files/Predictions_5000/KNN_predictions_df.parq')\n",
    "collab_predictions = collab_predictions.rename(columns = {'est':'prediction', 'uid':'userId', 'iid':'movieId'})\n",
    "collab_predictions = collab_predictions.drop(columns = ['r_ui', 'details.actual_k', 'details.was_impossible'])\n",
    "df2 = collab_predictions.copy()\n",
    "\n",
    "with open('processed_files/sparse_metadata', \"rb\") as f:\n",
    "    cols1 = pickle.load(f)\n",
    "    movieIds = pickle.load(f)\n",
    "    \n",
    "with open('processed_files/sparse_metadata_text', \"rb\") as f:\n",
    "    cols2 = pickle.load(f)\n",
    "    movieIds = pickle.load(f)\n",
    "cols2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movieId lists for movies with and without tags so can specify which movies to keep for which models\n",
    "with open('processed_files/movieIds_tags', \"rb\") as f:\n",
    "    movieIds_tags = pickle.load(f)\n",
    "with open('processed_files/movieIds_notags', \"rb\") as f:\n",
    "    movieIds_notags = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which movies we want to keep for evaluation and for generating recommendations \n",
    "keep_movies = movieIds # evaluate against\n",
    "keep_movies1 = [] # generate recs from model 1 (df1) - if [] then all movies\n",
    "keep_movies2 = [] # generate recs from model 2 (df2) - if [] then all movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of users to consider for random sampling\n",
    "#list_user = set(ratings.userId)\n",
    "list_user = set(collab_predictions.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use to get a subset of columns from processed_df_all_meta_sparse\n",
    "#index = [cols.index(i) for i in cols if i.startswith('production') | i.startswith('genres') | i.startswith('actors') |\n",
    "#        i.startswith('director')]\n",
    "#df = df[:, index]\n",
    "#cols = [cols[i] for i in index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters\n",
    "- n = # number of users\n",
    "- top_n = # top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "top_n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top n recommendations with movieIds\n",
    "def user_movie_id(movies,n):\n",
    "    return movies['movieId'][:n]\n",
    "\n",
    "# get top n recommendations with average raitngs\n",
    "def user_avg_rating(movies,n):\n",
    "    return movies['Average_Ratings'][:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify recommendation system(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_system_input1 = recommendation_models.content_based_recommendations.user_content_recommendations\n",
    "recommendation_system_input2 = recommendation_models.collab_recommendations.collab_recommendations\n",
    "#recommendation_system_input1 = False\n",
    "#recommendation_system_input2 = False\n",
    "\n",
    "#recommendation_system = recommendation_models.content_based_recommendations.user_content_recommendations\n",
    "#recommendation_system = recommendation_models.content_based_recommendations_combine.content_models_combine\n",
    "#recommendation_system = recommendation_models.collab_recommendations.collab_recommendations\n",
    "recommendation_system = recommendation_models.collab_content_recommendations_combine.collab_content_combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open file to record evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"evaluations/collab_content_combine_5000users.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalization \n",
    "How different are recommendations for different users? Are our recomendations actually personalized?    \n",
    "     \n",
    "K fold cross-validation across several sets of users\n",
    "- Generate recommendations for n users\n",
    "- Create movie matrix with row = user, column = movie, value = 1/0 for if movie recommended\n",
    "- Cosine similarity between users. Average of elements above the diagonal\n",
    "- Repeat for k folds and take overall average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return user predictions for each user in users_list\n",
    "# return list of all predictions for users in user_list\n",
    "def get_users_prediction(users_list,top_n,users_prediction,recommendation_system, df1, ratings, movieIds, movies_ratings,\n",
    "                         keep_movies1, df2 = False, keep_movies2 = False,\n",
    "                         recommendation_system_input1 = False, recommendation_system_input2 = False):\n",
    "    for i in users_list:\n",
    "        # generate recommendations \n",
    "        recommendation = recommendation_system(i, df1, ratings, movieIds, movies_ratings, keep_movies1, \n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        # top_n recommendations\n",
    "        prediction = user_movie_id(recommendation,top_n).astype(int).values\n",
    "        # append to list of predictions\n",
    "        users_prediction = users_prediction.append(pd.Series(prediction),ignore_index=True)\n",
    "        \n",
    "    return users_prediction\n",
    "\n",
    "# generate movie matrix: \n",
    "# row = user; column = movie ; value = 0 movie not recommended, 1 movie recommended\n",
    "def user_matrix(users_pred):\n",
    "    data_melt= pd.DataFrame(data=users_pred).reset_index().melt(id_vars='index', value_name='movieId',)\n",
    "    data_melt = data_melt[['index', 'movieId']].pivot(index='index', columns='movieId', values='movieId')\n",
    "    cols = data_melt.columns\n",
    "    \n",
    "    # replace na with 0\n",
    "    for i in cols:\n",
    "        data_melt[i] = np.where(data_melt[i].isna(), 0, 1)\n",
    "        \n",
    "    return data_melt\n",
    "\n",
    "# generating cosine similarity between the users. Same movie recommended for multiple users? \n",
    "# then getting the indicies of elements above diagonal (giving diagonal offsert =1 in triu_indices)\n",
    "# calculating the avg of the element above diagonal \n",
    "# Personalization means 1 - similarity\n",
    "# higher the personalization score, better the recommendation system in recommending personalized movies (minimize similarity)\n",
    "def personalization(users_matrix,n):\n",
    "   \n",
    "    # cosine similiarity\n",
    "    users_sim = metrics.pairwise.cosine_similarity(users_matrix)\n",
    "    \n",
    "    # upper triangle\n",
    "    iu1 = np.triu_indices(n,k=1)\n",
    "    \n",
    "    # average in upper \n",
    "    similarity_avg = np.mean(users_sim[iu1])\n",
    "    \n",
    "    # 1 - similarity. Want to maximize score (minimize similarity)\n",
    "    personalization_score = 1 - similarity_avg\n",
    "\n",
    "    return personalization_score\n",
    "\n",
    "\n",
    "# evaluate personalization on k random folds. Mean. \n",
    "def cross_fold_eval(unique_users,recommendation_system, movies_ratings, df1, keep_movies1, \n",
    "                    df2 = False, keep_movies2 = False, \n",
    "                    recommendation_system_input1 = False, recommendation_system_input2 = False, \n",
    "                    k_fold=10,n=10,top_n=10):\n",
    "    \n",
    "    # initiate to sum scores across folds (take average at end)\n",
    "    kfold_personalization=0\n",
    "    \n",
    "    # look through k folds\n",
    "    for i in range(k_fold):\n",
    "        \n",
    "        # generate list of n random users\n",
    "        users_list = random.sample(unique_users, n)\n",
    "        \n",
    "        # columns: top_n recommendations\n",
    "        # users_prediction:  top_n recommendations for n users. \n",
    "        column_names = list(range(top_n))\n",
    "        users_prediction = pd.DataFrame(columns = column_names)\n",
    "                \n",
    "        # getting predictions for all sampled users\n",
    "        users_pred = get_users_prediction(users_list,top_n,users_prediction,recommendation_system, \n",
    "                                          df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                          df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        \n",
    "        # getting user by movies matrix with binary indicators 0: movie not recommended, 1: movie got recommended\n",
    "        users_matrix = user_matrix(users_pred)\n",
    "        \n",
    "        # find personalization score based on movie matrix. Sum across folds \n",
    "        kfold_personalization+=personalization(users_matrix,n)\n",
    "        \n",
    "        \n",
    "    # average across all folds\n",
    "    kfold_eval = kfold_personalization/k_fold\n",
    "    \n",
    "    # write to file \n",
    "    print(f'Personalization score for {k_fold} folds across {n} users for top {top_n} recommendations: {kfold_eval}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get unique user set \n",
    "# K-fold cross validation for personalization score \n",
    "cross_fold_eval(list_user,recommendation_system, movies_ratings, df1, keep_movies1, df2, keep_movies2,\n",
    "                recommendation_system_input1, recommendation_system_input2, n = n, top_n = top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall \n",
    "- Generate train/test split among users that have at least 20 rated target movies\n",
    "- Generate recommendations on train, see if got any \"correct\" from test. Calculate precision, recall\n",
    "- Average across users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples of users who have rated minimum of 20 movies OUT OF target movies (keep_movies)\n",
    "Need enough movie ratings to do a reasonable train/test split. \n",
    "- keep_movies: universe of movie we want to calculate precision and recall in \n",
    "- n_users: Number of users to filter the from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of users who rated at least 20 movies: 5000\n"
     ]
    }
   ],
   "source": [
    "def target_users(ratings, keep_movies, list_user, n_users = 1000):\n",
    "    \n",
    "    # keep users with at least 20 ratings out of target movies (keep_movies)\n",
    "    users_list = ratings[(ratings.movieId.isin(keep_movies)) & (ratings.userId.isin(list_user))\n",
    "                        ].groupby('userId')['userId'].count().reset_index(name=\"rating_count\")\n",
    "    users_list = set(users_list[users_list['rating_count']>=20]['userId'].values)\n",
    "    print(f' Number of users who rated at least 20 movies: {len(users_list)}')\n",
    "    \n",
    "    # random sample of n_users \n",
    "    random.seed(42)\n",
    "    random_users = random.sample(users_list, min(n_users, len(users_list)))\n",
    "    # get the ratings of the random sample of users\n",
    "    users_ratings = ratings[ratings.userId.isin(random_users)]\n",
    "    \n",
    "    return users_ratings, random_users\n",
    "\n",
    "users_ratings, random_users_20 = target_users(ratings, keep_movies, list_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test split - Keeping the users distribution similar\n",
    "Select subset of users and then split each user's ratings into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(random_users, users_ratings):\n",
    "    \n",
    "    # creating train/test empty dataframe\n",
    "    train = pd.DataFrame(columns=['index','userId', 'movieId', 'rating','timestamp'])\n",
    "    test = pd.DataFrame(columns=['index','userId', 'movieId', 'rating','timestamp'])\n",
    "\n",
    "    # spliting each user data equally in train test\n",
    "    for i in random_users:\n",
    "        \n",
    "        #getting individual user index in the users_ratings list\n",
    "        random_index =set(users_ratings[users_ratings['userId'] == i].index.values)\n",
    "\n",
    "        # dividing the user ratings count/2\n",
    "        n_len = np.math.floor(len(random_index)/2)\n",
    "\n",
    "        # getting index for train data: random half of that user's ratings\n",
    "        train_ind = set(random.sample(random_index, n_len))\n",
    "\n",
    "        # getting index for test data by removing train index from all index for that user\n",
    "        test_ind = set(random_index-train_ind)\n",
    "\n",
    "        # assign indexes to train, test set\n",
    "        df_train = users_ratings.loc[train_ind]\n",
    "        df_test = users_ratings.loc[test_ind]\n",
    "        \n",
    "        # appending that user data to train/test df\n",
    "        train = train.append(df_train)\n",
    "        test = test.append(df_test)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(random_users_20, users_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Precision, Recall across random users\n",
    "- Generate recommendations based on training data. See if get movies from the test data that the user actually liked\n",
    "- Relevant item: Has in test with rating >= 2 \n",
    "    - Generous definition of relevant because hard to get precision, recall without user feedback. \n",
    "    - Limit to movies in keep_movies set. Only movies possibly being generated by model\n",
    "- Precision@k = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
    "- Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision@K = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
    "def calc_precision_k(recommended_relevant_count,recommended_count):\n",
    "    precision_k = recommended_relevant_count/recommended_count\n",
    "    return precision_k\n",
    "\n",
    "# Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)   \n",
    "def calc_recall_k(recommended_relevant_count,relevant_count):\n",
    "    if relevant_count==0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall_k = recommended_relevant_count/relevant_count\n",
    "        return recall_k\n",
    "    \n",
    "# average precision and recall across random users\n",
    "def avg_precision_recall(random_userId, recommendation_system, train, test, keep_movies, movies_ratings, df1, keep_movies1, \n",
    "                         df2 = False, keep_movies2 = False, \n",
    "                         recommendation_system_input1 = False, recommendation_system_input2 = False,\n",
    "                         top_n = 10, k = 5):\n",
    "    \n",
    "    # lists to record\n",
    "    avg_precision=[]\n",
    "    avg_recall =[]\n",
    "    tot_rec_rel = []\n",
    "    \n",
    "    # if sparse matrix, then generating recommendations from a second set of recommendations\n",
    "    if type(df2) == scipy.sparse.csc.csc_matrix:\n",
    "        df_option = df2.copy()\n",
    "    # if dataframe, then generating collaborative filtering recommendations where need to use precision option with test set\n",
    "    if type(df2) == pd.core.frame.DataFrame:\n",
    "        df_option = test.copy()\n",
    "\n",
    "    \n",
    "    # look through user subset\n",
    "    for i in random_userId:\n",
    "        \n",
    "        # generate recommendations \n",
    "        recommendation = recommendation_system(i, df1, train, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df_option, keep_movies2, recommendation_system_input1, recommendation_system_input2,\n",
    "                                               precision = True)\n",
    "        # getting the recommended movies @k\n",
    "        recommended_movies = set(recommendation[:k].movieId)\n",
    "\n",
    "        # number of recommended movie @k\n",
    "        recommended_count = k\n",
    "        \n",
    "        # getting relevant movies, where ratings >= 2\n",
    "        # limit to keep movies as these are the only movies being possibly produced by the recommendation system \n",
    "        relevant_movies =set(test[(test.movieId.isin(keep_movies)) &\n",
    "                                  (test['userId']==i) & (test['rating']>=2) ]['movieId'].values)\n",
    "        # Total number of relevant movie\n",
    "        relevant_count = len(relevant_movies)\n",
    "        \n",
    "        # Getting movies that are relevant and recommended (set intersection)\n",
    "        recommended_relevant_movies = recommended_movies.intersection(relevant_movies)\n",
    "        \n",
    "        # number of relevant recommended movies\n",
    "        recommended_relevant_count = len(recommended_relevant_movies)\n",
    "        \n",
    "        # calculate precision, recall\n",
    "        precision_k = calc_precision_k(recommended_relevant_count,recommended_count)\n",
    "        recall_k = calc_recall_k(recommended_relevant_count,relevant_count)\n",
    "        \n",
    "        # record \n",
    "        avg_precision.append(precision_k)\n",
    "        avg_recall.append(recall_k)\n",
    "        tot_rec_rel.append(recommended_relevant_count) # absoute number of recommended relevant movies \n",
    "        \n",
    "    # take average across n users \n",
    "    precision_avg = np.mean(avg_precision)\n",
    "    recall_avg = np.mean(avg_recall)\n",
    "    rec_rel_avg = np.mean(tot_rec_rel)\n",
    "\n",
    "    return precision_avg, recall_avg, rec_rel_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of elligible users, get random subset of n from training data (same users as in test data)\n",
    "\n",
    "random.seed(42)\n",
    "train_user_id = set(train.userId.values)\n",
    "random_userId = random.sample(train_user_id, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate at several values of K__    \n",
    "Most informative is k = 10 because generally generating 10 recommendations for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "precision_k,recall_k, rec_rel_avg = avg_precision_recall(random_userId, recommendation_system,\n",
    "                                                         train, test, keep_movies, movies_ratings, \n",
    "                                                         df1, keep_movies1, df2, keep_movies2, \n",
    "                                                         recommendation_system_input1, recommendation_system_input2,\n",
    "                                                         top_n, k)\n",
    "print(f'Avg Precision at {k} for {n} users: {precision_k}', file = f)\n",
    "print(f'Avg Recall at {k} for {n} users: {recall_k}', file = f)\n",
    "print(f'Avg Number of relevant recommendations at {k} for {n} users: {rec_rel_avg}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Diversity\n",
    "How different are the movies that we are recommending to users? Content models tend to \"profile\" people and result in over-specialization where only provide one kind of recommendation. Ideally would provide some variety.   \n",
    "- Generate recommendations for random user \n",
    "- Get \"profile\" of each recommended movie (non zero features)\n",
    "- Find cosine similarity between recommended movies. Transform to distance so maximize\n",
    "- Average over n users\n",
    "\n",
    "\n",
    "__NOTE:__ movies are compared based on the features in the current model. ie if model based on tags features, then looking at diversity of tags. If model based on genres and actors, then looking at diversity of actors and genres.   \n",
    "- For combined models, diversity based off of baseline features in df1 (genre, actors, directors) so that all movies equally comparable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_diversity(top_n, rand_user, recommendation_system, movies_ratings, df1, df2, keep_movies1, keep_movies2, \n",
    "                       recommendation_system_input1, recommendation_system_input2, cols1):\n",
    "\n",
    "    length = len(rand_user)\n",
    "    \n",
    "    # storing diversity for n users\n",
    "    diversity =[]\n",
    "    # find diversity for each user\n",
    "    for u in range(length):\n",
    "        \n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "        \n",
    "        # get top_n recommended movies \n",
    "        prediction = user_movie_id(recommendation,top_n).astype(int).values\n",
    "        predicted_index = [movieIds.index(i) for i in prediction] \n",
    "        user_df = df1[predicted_index, :]\n",
    "        user_movie_features = pd.DataFrame()\n",
    "        \n",
    "        # get movie profiles: getting only the columns that have any value 1\n",
    "        for i in range(len(prediction)):\n",
    "            nonzero_cols = [cols1[j] for j in user_df[i,:].nonzero()[1]]\n",
    "            d = {k:1 for k in nonzero_cols}\n",
    "            d = pd.DataFrame(data = d, index = [prediction[i]])    \n",
    "            user_movie_features = pd.concat([user_movie_features, d])\n",
    "\n",
    "        # replace NaN with 0\n",
    "        user_movie_features = user_movie_features.fillna(0)\n",
    "        \n",
    "        # generating cosine similarity between the recommended movies\n",
    "        sim = metrics.pairwise.cosine_similarity(np.asmatrix(user_movie_features))\n",
    "\n",
    "        # above diagonal elements. Take average (1 - similarity so get distance, which we want to maximize)\n",
    "        iu1 = np.triu_indices(user_movie_features.shape[0],k=1)\n",
    "        avg = 1 - np.mean(sim[iu1])\n",
    "        \n",
    "        # keep track across n users\n",
    "        diversity.append(avg)\n",
    "        \n",
    "    # calculating avg diversity over n users\n",
    "    avg_diversity = np.mean(diversity)\n",
    "\n",
    "    return avg_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get list of n random users \n",
    "random.seed(42)\n",
    "rand_user = random.sample(list_user, n)  \n",
    "\n",
    "avg_diversity = personal_diversity(top_n, rand_user, recommendation_system, movies_ratings, \n",
    "                                   df1, df2, keep_movies1, keep_movies2, \n",
    "                                   recommendation_system_input1, recommendation_system_input2, cols1)\n",
    "print(f'Average diversity over {n} users for their top {top_n} recommendations (0 = identical): {avg_diversity}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Rating \n",
    "Want to recommend \"good\" movies with high average ratings    \n",
    "\n",
    "- Generate recommendations for random users\n",
    "- Merge in average ratings of the recommended movies\n",
    "- Take average of average ratings \n",
    "- Take average across random sample of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                   recommendation_system, recommendation_system_input1, recommendation_system_input2):\n",
    "    \n",
    "    length = len(rand_user)\n",
    "    avg_rating = []\n",
    "\n",
    "    # loop through users\n",
    "    for u in range(length):\n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "        # find average all movies' average ratings \n",
    "        prediction = user_avg_rating(recommendation,top_n).values\n",
    "\n",
    "        # keep track across users\n",
    "        avg_rating.append(prediction)\n",
    "\n",
    "    # flatten list \n",
    "        # can recommend movies without ratings so lists may be diff lengths: won't work in np.mean natively\n",
    "    avg_rating = [item for sublist in avg_rating for item in sublist]\n",
    "    \n",
    "    return avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random users out of users that have rated at least one of keep_movies\n",
    "list_user_keepmovies = set(ratings[(ratings.movieId.isin(keep_movies)) & (ratings.userId.isin(list_user))].userId)\n",
    "\n",
    "random.seed(42)\n",
    "rand_user = random.sample(list_user_keepmovies, n)  \n",
    "\n",
    "avg_rating = average_rating(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2,\n",
    "                            recommendation_system, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "print(f'Average movie rating of top {top_n} movies recommended to {n} users: {np.round(np.mean(avg_rating),2)}', file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Graph Distribution of Ratings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ratings - Recommended Movies')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = ['0-1', '1-2', '2-3', '3-4', '4-5']\n",
    "ad = pd.DataFrame(avg_rating).melt()\n",
    "ad['ratingrange'] = pd.cut(ad['value'], bins=[0,1,2,3,4,5], labels=ranges, right=True)\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "ax = ad.groupby(['ratingrange'])['ratingrange'].count().plot.bar()\n",
    "ax.set_ylabel('Number of Ratings')\n",
    "ax.set_xlabel('Recommended Movie Rating')\n",
    "ax.set_title('Ratings - Recommended Movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Diversity: Checking for the long tail\n",
    "Want to recommend some \"unpopular\" movies such that users view movies in the long tail that they otherwise would not be exposed to\n",
    "- Generate recommendations for random  users\n",
    "- Merge in count of number of reviews for the recommended movies\n",
    "- Take the minimum count (extent of the long tail)\n",
    "- Average minimum counts across random users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def global_diversity(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                     recommendation_system, recommendation_system_input1, recommendation_system_input2):\n",
    "\n",
    "    length = len(rand_user)\n",
    "    min_cnt = []\n",
    "\n",
    "    # loop through random users\n",
    "    for u in range(length):\n",
    "        # getting recommended movies\n",
    "        recommendation = recommendation_system(rand_user[u], df1, ratings, movieIds, movies_ratings, keep_movies1,\n",
    "                                               df2, keep_movies2, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "        # getting the min rating cnt of the movies recommended\n",
    "        min_rating_cnt = recommendation[:top_n]['cnt'].min()\n",
    "        \n",
    "        # keep track\n",
    "        min_cnt.append(min_rating_cnt)\n",
    "\n",
    "    # take average of minimum counts \n",
    "    avg_min_cnt = np.mean(min_cnt)\n",
    "    \n",
    "    return avg_min_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# random sample of n users \n",
    "rand_user = random.sample(list_user, n)  \n",
    "\n",
    "avg_min_cnt = global_diversity(rand_user, ratings, movies_ratings, movieIds, df1, df2, keep_movies1, keep_movies2, \n",
    "                               recommendation_system, recommendation_system_input1, recommendation_system_input2)\n",
    "\n",
    "print(f\"Average of the minimum count of ratings for {n} user's top {top_n} recommendations (long tail):{np.round(avg_min_cnt,2)}\",\n",
    "      file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
