{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate & Display Personalized Recommendations\n",
    "**Use Case**: User with existing profile OR generated one on Add Profile page. Provide personalized recommendations using models defined in modules. \n",
    "\n",
    "Process:\n",
    "- Combine ratings data with any newly created profiles\n",
    "- User enters ID\n",
    "- Check if personalized recommendations available -> collaborative-content combination model\n",
    "    - Pre-computed so will not include user added profiles in this session or prior sessions if retrain hasn't happened\n",
    "- Otherwise check if valid ID (in ratings dataset) -> content combination model \n",
    "- Generate recommendations: full recommendation list from each model\n",
    "    - Do not display recommenations if predicted will not like movie even if fit filter\n",
    "        - Content: cosine similarity must be greater than 0\n",
    "        - Collab: predicted rating must be greater than user's personal average movie rating \n",
    "- Allow user to select filters\n",
    "- Apply filters to each set of recommendations \n",
    "- Merge filtered down lists. Ideally get 5 from each, but if filters such that fewer than 5 available from one, get as many as possible and fill in the rest of the 10 from the other set. \n",
    "- Sort combined set on weighted average: present most popular movies at the top to gain credibility, and then present long tail movies to generate more streaming after have gained trust    \n",
    "- Display recommendations    \n",
    "   \n",
    "Note: if run this locally outside of app, data paths will be incorrect including recommendation system modules. Assuming running in streamlit, in which case main_app.py calls these scripts from the root folder, which is where the datasets live.    \n",
    "Also, data is being passed in from main_app, so not all required data is loaded/created in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "import operator\n",
    "import scipy.spatial.distance as distance\n",
    "from sklearn import metrics \n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import fastparquet\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import scipy\n",
    "from fuzzywuzzy import fuzz\n",
    "import sklearn\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import recommendation system (py scripts)\n",
    "from recommendation_models.content_based_recommendations import user_content_recommendations\n",
    "from recommendation_models.collab_recommendations import collab_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Called in data prep section main app     \n",
    "- Load two sparse matrices for the combined model. df1 is movie profiles with one hot encoded genre, (top 3) actors, directors. df2 is movie profiles with one hot encoded top 5 tfidf tokens from description+genome tags\n",
    "- Load corresponding columns and movieIds (row) for sparse matrices. Don't need columns and movieIds are identical in the two datasets, so load just for df1\n",
    "    - All movie ids in both datasets because want to generate user profile based on all movies they have rated. Then filter recommendations down to the target group\n",
    "- Precomputed collaborative filtering predictions from a subset of users\n",
    "- Load in ratings data. Version that is limited to users with collaborative filtering recommendations + with user profiles added on from prior runs of app \n",
    "    - If retraining hasn't occurred yet, can still use prior entered user profiles to get content based personalized recommendations\n",
    "- Load lists of movieIds with and without tags. Will generate recommendations from tagged movies with df2 and untagged movies with df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation=True)\n",
    "def load_data():\n",
    "      \n",
    "    # sparse movie dataframe with attached metadata (column titles, movieIds in row order)\n",
    "    # two datasets for combined models \n",
    "    df1 = scipy.sparse.load_npz(\"processed_files/processed_df_sparse.npz\")\n",
    "    df2 = scipy.sparse.load_npz(\"processed_files/processed_df_text_sparse.npz\")\n",
    "    \n",
    "    with open('processed_files/sparse_metadata', \"rb\") as f:\n",
    "        cols1 = pickle.load(f)\n",
    "        movieIds = pickle.load(f)\n",
    "\n",
    "    # precomputed collaborative filtering predictions\n",
    "    collab_predictions = pd.read_parquet('processed_files/Predictions_5000/KNN_predictions_df.parq')\n",
    "    # rename columns to be consistent \n",
    "    collab_predictions = collab_predictions.rename(columns = {'est':'prediction', 'uid':'userId', 'iid':'movieId'})\n",
    "    collab_predictions = collab_predictions.drop(columns = ['r_ui', 'details.actual_k', 'details.was_impossible'])\n",
    "        \n",
    "    # version of ratings that is limited to collab users + has manually entered user profiles added on \n",
    "    ratings = pd.read_parquet('processed_files/ratings_sample_useradd_collab.parq')\n",
    "    ratings = ratings.reset_index(drop = True)\n",
    "    \n",
    "    # load movieId lists for movies with and without tags so can specify which movies to keep for which models\n",
    "    with open('processed_files/movieIds_tags', \"rb\") as f:\n",
    "        movieIds_tags = pickle.load(f)\n",
    "    with open('processed_files/movieIds_notags', \"rb\") as f:\n",
    "        movieIds_notags = pickle.load(f)\n",
    "        \n",
    "    return ratings, movieIds, df1, df2, collab_predictions, movieIds_tags, movieIds_notags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ratings data with new profile created in this run of the app\n",
    "- If user entered any new ratings in Profile Add tab, they will be in lists of the ratings, userId, and movieIds\n",
    "- Create a dataframe and append onto existing ratings data to use for recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation = True)\n",
    "def create_ratings_df(new_ratings, new_users, new_movies, ratings):\n",
    "                \n",
    "    # create dataframe from lists of newly added from profile add\n",
    "    d = {'rating':new_ratings, 'userId':new_users, 'movieId':new_movies}\n",
    "    new_ratings = pd.DataFrame(d)\n",
    "    \n",
    "    # sometimes duplicate movies from user profile adds if they enter hte same movie twice\n",
    "        # take average of duplicate ratings. Else matrix multiplication won't work\n",
    "    new_ratings = new_ratings.groupby(['userId', 'movieId']).rating.mean()  \n",
    "    new_ratings = new_ratings.reset_index(drop = False)\n",
    "    \n",
    "    # concat with original ratings\n",
    "    ratings = pd.concat([ratings, new_ratings], sort = False)\n",
    "    ratings = ratings.reset_index(drop = True)\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Recommendations \n",
    "- Generate recommendations from specified system \n",
    "- Content: Limit recommendations to similarity > 0 so that when filtering, don't display something they would DISlike \n",
    "- Collab: Limit recommendations to predicted rating > user's personal average. Don't display something they would DISlike\n",
    "    - Also merge with df_display to get relevant features for display. Content model merge happens within module\n",
    "- Do not sort or combine sets here: dealt with after filtering   \n",
    "    - This is why we don't use the combination functions used in evaluations\n",
    "    \n",
    "Cached so that when entering filter values, do not re-generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation = True)\n",
    "def content_recommendations(user_id, df1, df2, df_display, ratings, movieIds, keep_movies1, keep_movies2): \n",
    "    \n",
    "    # generate two sets of recommendations \n",
    "    recommend1 = user_content_recommendations(user_id, df1, ratings, movieIds, df_display, keep_movies1)\n",
    "    recommend2 = user_content_recommendations(user_id, df2, ratings, movieIds, df_display, keep_movies2)\n",
    "    \n",
    "    # limit to recommendations similarity > 0 \n",
    "        # don't recommend movies that are similar to movies they dislike\n",
    "    recommend1 = recommend1[recommend1.prediction > 0]\n",
    "    recommend2 = recommend2[recommend2.prediction > 0]\n",
    "\n",
    "    return recommend1, recommend2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation = True)\n",
    "def collab_content_recommendations(user_id, df1, collab_predictions, df_display, ratings, movieIds): \n",
    "    \n",
    "    collab_rec = collab_recommendations(user_id, df1, ratings, movieIds, df_display, [], collab_predictions, [])\n",
    "\n",
    "    # find movies in full set that are not in collaborative filtering predictions for this user\n",
    "    keep_movies = set(movieIds).difference(set(collab_rec.movieId.unique()))\n",
    "    \n",
    "    # generate recommendations from content model with movies not in collab filtering\n",
    "    content_rec = user_content_recommendations(user_id, df1, ratings, movieIds, df_display, keep_movies)\n",
    "    \n",
    "    # limit content recs to similarity > 0 \n",
    "    content_rec = content_rec[content_rec.prediction > 0]\n",
    "\n",
    "    # limit collabs recs to predicted rating > user's average rating\n",
    "    collab_rec = collab_rec[collab_rec.prediction > ratings[ratings.userId == user_id].rating.mean()]\n",
    "    \n",
    "    return collab_rec, content_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit App\n",
    "- See notes on filtering options in non_user_recommendations script/notebook. Identical filter options here. \n",
    "- Combine existing ratings with profiles newly created in the 'add profile' tab of UI. Then if enter userId generated there, will be able to produce recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation=True)\n",
    "def fuzzy_matching(user_input, original_df, var):\n",
    "    # downcase input\n",
    "    user_input = user_input.lower()\n",
    "    # split into list based on commas\n",
    "    user_input = user_input.split(', ')\n",
    "\n",
    "    # fuzzy string matching to find similarity ratio between user input and actual actors (downcased)\n",
    "        # works for misspellings as well \n",
    "        # limit to 70% similarity \n",
    "    options = []\n",
    "    sim_df = original_df.copy()\n",
    "    for i in user_input:\n",
    "        # find similarity ratio between input and all unique actors (downcased)\n",
    "        sim_df['sim'] = sim_df[var + '_downcased'].apply(lambda row: fuzz.token_sort_ratio(row, i))\n",
    "        # get top 3 with similarity > 70%\n",
    "        options.append(sim_df[sim_df.sim > 70].sort_values('sim', ascending = False\n",
    "                                                          ).head(3)[var + '_upcased'].unique())\n",
    "    # flatten options list\n",
    "    options = [item for sublist in options for item in sublist]    \n",
    "\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(df_display, genres_unique, actors_df, directors_df, countries_unique,\n",
    "          language_unique, tags_unique, decades_unique, new_ratings, new_users, new_movies, ratings, movieIds,\n",
    "          collab_predictions, df1, df2, keep_movies1, keep_movies2):\n",
    "    \n",
    "    # user instructions \n",
    "    st.title('Personalized Movie Recommendations')\n",
    "    st.write('Select **Display Recommendations** with no inputs to view your top recommendations. \\n' + \n",
    "             'Or select filters to see your top recommended movies in those categories.')\n",
    "    \n",
    "    # combine original ratings with newly created profiles\n",
    "    ratings = create_ratings_df(new_ratings, new_users, new_movies, ratings)\n",
    "\n",
    "    # user enter their user ID\n",
    "    userId = st.text_input('Enter your User ID:')\n",
    "    \n",
    "    # initial state is ''\n",
    "    if userId == '':\n",
    "        st.write('Cannot provide recommendations without an ID')\n",
    "    else:\n",
    "        # check if valid integer. If yes, convert\n",
    "        try:\n",
    "            userId_int = int(userId)\n",
    "        # if cannot convert to an integer \n",
    "        except ValueError:\n",
    "            st.write('Not a valid ID')\n",
    "            \n",
    "        # if valid integer, find if ID is in collaborative filtering set or not. \n",
    "        # this will not including newly entered user profiles\n",
    "        else: \n",
    "            if userId_int in set(collab_predictions.userId.unique()):\n",
    "                \n",
    "                # generate recommendations form collab-content combined model\n",
    "                recommend1, recommend2 = collab_content_recommendations(userId_int, df1, collab_predictions, \n",
    "                                                                        df_display, ratings, movieIds)\n",
    "                recommend1 = recommend1.drop(columns = ['userId'])\n",
    "                \n",
    "            # if not in collab filtering, check if valid ID and produce content based recommendations. Newly entered profiles.\n",
    "            elif userId_int in set(ratings.userId.unique()):\n",
    "                \n",
    "                # generate recommendations from combined content model \n",
    "                recommend1, recommend2 = content_recommendations(userId_int, df1, df2, df_display, ratings, movieIds,\n",
    "                                                                 keep_movies1, keep_movies2)\n",
    "\n",
    "            # only other option is not valid recommendation\n",
    "            else:\n",
    "                st.write('Not a valid ID')\n",
    "                recommend1 = pd.DataFrame() # empty dataframe so next if statement does not execute\n",
    "                \n",
    "            if len(recommend1) > 0: \n",
    "            \n",
    "                ## filtering \n",
    "                # get user inputs: multiple selection possible per category except decade\n",
    "                # input sorted list of unique options \n",
    "                genre_input = st.multiselect('Select genre(s)', genres_unique)\n",
    "                decade_input = st.selectbox('Select film decade', ['Choose an option'] + list(decades_unique))\n",
    "                country_input = st.multiselect('Select filming country(s)', countries_unique)\n",
    "                language_input = st.multiselect('Select language(s)', language_unique)\n",
    "                tag_input = st.multiselect('Select genome tags(s)', tags_unique)\n",
    "\n",
    "                # actors, directors get text inputs - dropdowns too many values for streamlit to handle\n",
    "                # allow multiple entries with a commoa \n",
    "                actor_input = st.text_input('Type actor(s) names separated by commas. Select intended actor(s) from dropdown that appears')\n",
    "                if actor_input != '':\n",
    "\n",
    "                    options = fuzzy_matching(actor_input, actors_df, 'actors')\n",
    "\n",
    "                    # list actors that are similar to what they typed and accept user selection(s)\n",
    "                    if len(options) > 0:\n",
    "                        actor_input = st.multiselect('Select Actor(s)', options)\n",
    "                    else:\n",
    "                        st.write(\"Sorry, we can't find any matching actors\")\n",
    "\n",
    "                else:\n",
    "                    actor_input = []\n",
    "\n",
    "                director_input = st.text_input('Type director(s) names separated by commas. ' + \n",
    "                                               'Select intended director(s) from dropdown that appears')\n",
    "                if director_input != '':\n",
    "\n",
    "                    options = fuzzy_matching(director_input, directors_df, 'directors')\n",
    "\n",
    "                    # list directors that are similar to what they typed and accept user selection(s)\n",
    "                    if len(options) > 0:\n",
    "                        director_input = st.multiselect('Select Director(s)', options)\n",
    "                    else:\n",
    "                        st.write(\"Sorry, we can't find any matching directors\")\n",
    "\n",
    "                else:\n",
    "                    director_input = []\n",
    "\n",
    "                # display recommendations once hit button\n",
    "                if st.button('Display Recommendations'):\n",
    "                \n",
    "                    # filter recommendation sets based on filters\n",
    "                    rec1_filtered = recommend1[(recommend1.Genres.map(set(genre_input).issubset)) & \n",
    "                                                (recommend1['Filming Countries'].map(set(country_input).issubset)) &\n",
    "                                                (recommend1['Language(s)'].map(set(language_input).issubset)) & \n",
    "                                                (recommend1.Tags.map(set(tag_input).issubset))  & \n",
    "                                                (recommend1['Actors'].map(set(actor_input).issubset)) &\n",
    "                                                (recommend1['Director(s)'].map(set(director_input).issubset)) \n",
    "                                               ].sort_values(['prediction', 'weighted_avg'], ascending = False)\n",
    "                    rec2_filtered = recommend2[(recommend2.Genres.map(set(genre_input).issubset)) & \n",
    "                                                (recommend2['Filming Countries'].map(set(country_input).issubset)) &\n",
    "                                                (recommend2['Language(s)'].map(set(language_input).issubset)) & \n",
    "                                                (recommend2.Tags.map(set(tag_input).issubset))  & \n",
    "                                                (recommend2['Actors'].map(set(actor_input).issubset)) &\n",
    "                                                (recommend2['Director(s)'].map(set(director_input).issubset)) \n",
    "                                               ].sort_values(['prediction', 'weighted_avg'], ascending = False)\n",
    "                    # for decade, only filter if chose an option (no NA default for selectbox)\n",
    "                    if decade_input != 'Choose an option':\n",
    "                        rec1_filtered = rec1_filtered[(rec1_filtered.decade == decade_input)]\n",
    "                        rec2_filtered = rec2_filtered[(rec2_filtered.decade == decade_input)]\n",
    "                        \n",
    "                    # Merge filtered down lists. \n",
    "                    # Ideally get 5 from each, but if filters such that fewer than 5 available from one, \n",
    "                    # get as many as possible and fill in the rest of the 10 from the other set\n",
    "                    if len(rec1_filtered) >= 5 and len(rec2_filtered) >= 5:\n",
    "                        rec_filtered = pd.concat([rec1_filtered.head(int(5)), rec2_filtered.head(int(5))])  \n",
    "                    elif len(rec1_filtered) < 5:\n",
    "                        rec_filtered = pd.concat([rec1_filtered, rec2_filtered.head(int(10 - len(rec1_filtered)))])  \n",
    "                    elif len(rec2_filtered) < 5:\n",
    "                        rec_filtered = pd.concat([rec1_filtered.head(int(10 - len(rec1_filtered))), rec2_filtered])  \n",
    "\n",
    "                    # sort combination based on weighted average\n",
    "                    rec_filtered = rec_filtered.sort_values('weighted_avg', ascending = False)\n",
    "                    \n",
    "                    # drop unnecessary columns for display\n",
    "                    rec_filtered = rec_filtered.drop(columns = ['weighted_avg', 'actors_downcased', \n",
    "                                                                'directors_downcased', 'title_downcased', \n",
    "                                                                'title_year', 'movieId', 'prediction',\n",
    "                                                                'decade', 'tags_num'])\n",
    "                        \n",
    "                    # if no valid movies with combination of filters, notify. Else display dataframe\n",
    "                    if len(rec_filtered) > 0:\n",
    "                        st.write(rec_filtered)\n",
    "                    else:\n",
    "                        st.write('Found no recommended movies that match your selections')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
